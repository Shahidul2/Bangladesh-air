{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4ce407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PI-GNN | h=24 | k=3\n",
      "============================================================\n",
      "[k=3] ep 01 | train 17.2587 | val_MAE 15.1624 | val_RMSE 22.4972 | val_viol 35.49% | D 0.6475 k 0.2948\n",
      "[k=3] ep 02 | train 11.9904 | val_MAE 14.8532 | val_RMSE 21.9255 | val_viol 36.84% | D 0.4990 k 0.2972\n",
      "[k=3] ep 03 | train 11.6149 | val_MAE 14.5831 | val_RMSE 21.3843 | val_viol 38.75% | D 0.4038 k 0.2989\n",
      "[k=3] ep 04 | train 11.4129 | val_MAE 14.6269 | val_RMSE 21.6229 | val_viol 34.53% | D 0.3415 k 0.3009\n",
      "[k=3] ep 05 | train 11.2432 | val_MAE 14.7396 | val_RMSE 21.9484 | val_viol 32.10% | D 0.3016 k 0.3018\n",
      "[k=3] ep 06 | train 11.1488 | val_MAE 14.4789 | val_RMSE 21.3944 | val_viol 35.21% | D 0.2797 k 0.3018\n",
      "[k=3] ep 07 | train 11.1038 | val_MAE 14.2778 | val_RMSE 20.8339 | val_viol 38.57% | D 0.2677 k 0.3013\n",
      "[k=3] ep 08 | train 11.0257 | val_MAE 14.2522 | val_RMSE 20.9564 | val_viol 35.77% | D 0.2634 k 0.3012\n",
      "[k=3] ep 09 | train 10.9645 | val_MAE 14.4333 | val_RMSE 21.3673 | val_viol 34.31% | D 0.2642 k 0.3008\n",
      "[k=3] ep 10 | train 10.9119 | val_MAE 14.2533 | val_RMSE 21.1078 | val_viol 34.76% | D 0.2654 k 0.2997\n",
      "[k=3] ep 11 | train 10.9371 | val_MAE 14.1559 | val_RMSE 20.9279 | val_viol 35.08% | D 0.2660 k 0.2996\n",
      "[k=3] ep 12 | train 10.8816 | val_MAE 14.3223 | val_RMSE 21.3988 | val_viol 32.20% | D 0.2707 k 0.2993\n",
      "[k=3] ep 13 | train 10.8454 | val_MAE 14.3549 | val_RMSE 21.3913 | val_viol 33.78% | D 0.2749 k 0.2986\n",
      "[k=3] ep 14 | train 10.8075 | val_MAE 14.8533 | val_RMSE 22.6210 | val_viol 30.16% | D 0.2809 k 0.2983\n",
      "[k=3] ep 15 | train 10.8223 | val_MAE 14.2535 | val_RMSE 21.2513 | val_viol 33.27% | D 0.2832 k 0.2976\n",
      "[k=3] Early stop. Best val_MAE=14.1559\n",
      "\n",
      "============================================================\n",
      "PI-GNN | h=24 | k=5\n",
      "============================================================\n",
      "[k=5] ep 01 | train 18.0027 | val_MAE 15.2804 | val_RMSE 22.5544 | val_viol 35.32% | D 0.5944 k 0.2941\n",
      "[k=5] ep 02 | train 12.0494 | val_MAE 14.8678 | val_RMSE 21.8268 | val_viol 37.52% | D 0.4650 k 0.2979\n",
      "[k=5] ep 03 | train 11.5920 | val_MAE 14.6100 | val_RMSE 21.4163 | val_viol 37.09% | D 0.3767 k 0.3020\n",
      "[k=5] ep 04 | train 11.3613 | val_MAE 14.5967 | val_RMSE 21.6989 | val_viol 31.94% | D 0.3160 k 0.3061\n",
      "[k=5] ep 05 | train 11.1941 | val_MAE 14.4241 | val_RMSE 21.3137 | val_viol 33.30% | D 0.2766 k 0.3083\n",
      "[k=5] ep 06 | train 11.0744 | val_MAE 14.3179 | val_RMSE 21.0830 | val_viol 34.24% | D 0.2511 k 0.3097\n",
      "[k=5] ep 07 | train 10.9842 | val_MAE 14.4924 | val_RMSE 21.4738 | val_viol 32.96% | D 0.2384 k 0.3104\n",
      "[k=5] ep 08 | train 10.9381 | val_MAE 14.3111 | val_RMSE 21.0970 | val_viol 34.91% | D 0.2298 k 0.3104\n",
      "[k=5] ep 09 | train 10.9035 | val_MAE 14.0730 | val_RMSE 20.7614 | val_viol 34.98% | D 0.2271 k 0.3102\n",
      "[k=5] ep 10 | train 10.8841 | val_MAE 14.1239 | val_RMSE 20.9724 | val_viol 31.70% | D 0.2233 k 0.3106\n",
      "[k=5] ep 11 | train 10.8017 | val_MAE 14.1311 | val_RMSE 20.8629 | val_viol 34.33% | D 0.2234 k 0.3098\n",
      "[k=5] ep 12 | train 10.7845 | val_MAE 14.0690 | val_RMSE 20.7519 | val_viol 34.65% | D 0.2243 k 0.3094\n",
      "[k=5] ep 13 | train 10.7610 | val_MAE 14.0824 | val_RMSE 20.4073 | val_viol 40.93% | D 0.2251 k 0.3082\n",
      "[k=5] ep 14 | train 10.7268 | val_MAE 14.2240 | val_RMSE 21.1808 | val_viol 32.30% | D 0.2270 k 0.3084\n",
      "[k=5] ep 15 | train 10.6979 | val_MAE 14.1189 | val_RMSE 20.7923 | val_viol 35.62% | D 0.2283 k 0.3074\n",
      "[k=5] ep 16 | train 10.6907 | val_MAE 14.1476 | val_RMSE 20.6862 | val_viol 37.54% | D 0.2287 k 0.3068\n",
      "[k=5] Early stop. Best val_MAE=14.0690\n",
      "\n",
      "============================================================\n",
      "PI-GNN | h=24 | k=6\n",
      "============================================================\n",
      "[k=6] ep 01 | train 18.2091 | val_MAE 15.1979 | val_RMSE 22.3629 | val_viol 36.94% | D 0.5446 k 0.2945\n",
      "[k=6] ep 02 | train 12.2105 | val_MAE 14.9356 | val_RMSE 22.0841 | val_viol 34.76% | D 0.4297 k 0.2997\n",
      "[k=6] ep 03 | train 11.7833 | val_MAE 14.8374 | val_RMSE 21.7820 | val_viol 36.45% | D 0.3410 k 0.3044\n",
      "[k=6] ep 04 | train 11.4760 | val_MAE 14.4531 | val_RMSE 21.1615 | val_viol 37.29% | D 0.2776 k 0.3084\n",
      "[k=6] ep 05 | train 11.2497 | val_MAE 14.3446 | val_RMSE 21.0044 | val_viol 36.60% | D 0.2377 k 0.3116\n",
      "[k=6] ep 06 | train 11.0867 | val_MAE 14.6191 | val_RMSE 21.5688 | val_viol 34.00% | D 0.2193 k 0.3132\n",
      "[k=6] ep 07 | train 10.9765 | val_MAE 14.2937 | val_RMSE 21.0211 | val_viol 35.12% | D 0.2094 k 0.3131\n",
      "[k=6] ep 08 | train 10.9030 | val_MAE 14.1696 | val_RMSE 20.9531 | val_viol 34.03% | D 0.2048 k 0.3130\n",
      "[k=6] ep 09 | train 10.8556 | val_MAE 14.1044 | val_RMSE 20.8351 | val_viol 34.34% | D 0.2020 k 0.3126\n",
      "[k=6] ep 10 | train 10.7723 | val_MAE 14.4067 | val_RMSE 21.3638 | val_viol 33.50% | D 0.2021 k 0.3121\n",
      "[k=6] ep 11 | train 10.7413 | val_MAE 14.0156 | val_RMSE 20.5299 | val_viol 36.72% | D 0.2030 k 0.3109\n",
      "[k=6] ep 12 | train 10.7148 | val_MAE 14.0744 | val_RMSE 20.8314 | val_viol 34.25% | D 0.2053 k 0.3103\n",
      "[k=6] ep 13 | train 10.7160 | val_MAE 14.1299 | val_RMSE 20.8947 | val_viol 34.61% | D 0.2077 k 0.3093\n",
      "[k=6] ep 14 | train 10.6389 | val_MAE 14.1583 | val_RMSE 21.0857 | val_viol 33.47% | D 0.2102 k 0.3085\n",
      "[k=6] ep 15 | train 10.6548 | val_MAE 13.8760 | val_RMSE 20.4267 | val_viol 35.49% | D 0.2136 k 0.3072\n",
      "[k=6] ep 16 | train 10.6260 | val_MAE 13.9397 | val_RMSE 20.3942 | val_viol 37.99% | D 0.2139 k 0.3063\n",
      "[k=6] ep 17 | train 10.5864 | val_MAE 14.0395 | val_RMSE 20.6597 | val_viol 36.78% | D 0.2165 k 0.3051\n",
      "[k=6] ep 18 | train 10.5731 | val_MAE 14.3018 | val_RMSE 21.1753 | val_viol 35.18% | D 0.2210 k 0.3047\n",
      "[k=6] ep 19 | train 10.5541 | val_MAE 13.9491 | val_RMSE 20.3912 | val_viol 38.16% | D 0.2233 k 0.3030\n",
      "[k=6] Early stop. Best val_MAE=13.8760\n",
      "\n",
      "Saved: metrics_k_sensitivity_pignn_h24.csv\n",
      "    model  k_graph  horizon_h    val_MAE   val_RMSE  val_viol_rate  test_MAE  \\\n",
      "2  PI-GNN        6         24  13.876048  20.426743       0.354893  9.319936   \n",
      "0  PI-GNN        3         24  14.155926  20.927904       0.350789  9.418149   \n",
      "1  PI-GNN        5         24  14.069033  20.751904       0.346526  9.514884   \n",
      "\n",
      "   test_RMSE  test_viol_rate     D_eff     k_eff  \n",
      "2  14.281901        0.394867  0.213625  0.307233  \n",
      "0  14.534042        0.403409  0.266017  0.299630  \n",
      "1  14.653114        0.338952  0.224296  0.309353  \n"
     ]
    }
   ],
   "source": [
    "# k-sensitivity, h=24\n",
    "# Metrics: MAE, RMSE, viol_rate (val + test)\n",
    "# Runs: k = 3, 5, 6 (k=4 already done)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "DATA_PATH = \"dataset_2023_2025.csv\"\n",
    "\n",
    "H = 24\n",
    "LAGS = [1, 2, 6, 24]\n",
    "\n",
    "TRAIN_END = \"2024-12-31 23:00:00\"\n",
    "VAL_END   = \"2025-06-30 23:00:00\"\n",
    "TEST_END  = \"2025-11-23 23:00:00\"\n",
    "\n",
    "ELL_KM = 120.0\n",
    "K_LIST = [3, 5, 6]  \n",
    "\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_TIMES = 128\n",
    "EPOCHS = 30\n",
    "PATIENCE = 4\n",
    "LR = 2e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "\n",
    "DT = 1.0\n",
    "GAMMA = 1.0\n",
    "\n",
    "# full PI-GNN constraints\n",
    "LAMBDA_INEQ = 0.30\n",
    "LAMBDA_NONNEG = 0.05\n",
    "\n",
    "DROPOUT = 0.20\n",
    "\n",
    "SAVE_PREDICTIONS = False\n",
    "OUT_MET = \"metrics_k_sensitivity_pignn_h24.csv\"\n",
    "OUT_PRED = \"predictions_pignn_k_sensitivity_h24.csv\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Helpers\n",
    "def make_lag_features(df, lags):\n",
    "    df = df.sort_values([\"city_id\",\"datetime\"]).copy()\n",
    "    for lag in lags:\n",
    "        df[f\"pm2_5_lag{lag}\"] = df.groupby(\"city_id\")[\"pm2_5\"].shift(lag)\n",
    "    return df\n",
    "\n",
    "def make_targets(df, h):\n",
    "    df = df.sort_values([\"city_id\",\"datetime\"]).copy()\n",
    "    df[f\"y_h{h}\"] = df.groupby(\"city_id\")[\"pm2_5\"].shift(-h)\n",
    "    df[f\"pm10_h{h}\"] = df.groupby(\"city_id\")[\"pm10\"].shift(-h)\n",
    "    return df\n",
    "\n",
    "def time_split_times(times):\n",
    "    times = pd.to_datetime(times)\n",
    "    tr = times[times <= pd.Timestamp(TRAIN_END)]\n",
    "    va = times[(times > pd.Timestamp(TRAIN_END)) & (times <= pd.Timestamp(VAL_END))]\n",
    "    te = times[(times > pd.Timestamp(VAL_END)) & (times <= pd.Timestamp(TEST_END))]\n",
    "    return tr, va, te\n",
    "\n",
    "def build_knn_graph(city_meta, k=4, ell_km=120.0):\n",
    "    coords = city_meta[[\"lat\",\"lon\"]].to_numpy()\n",
    "    coords_rad = np.radians(coords)\n",
    "\n",
    "    nnm = NearestNeighbors(n_neighbors=k+1, metric=\"haversine\").fit(coords_rad)\n",
    "    dists, idxs = nnm.kneighbors(coords_rad)\n",
    "\n",
    "    n = len(coords)\n",
    "    W = np.zeros((n,n), dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        for t in range(1, k+1):\n",
    "            j = idxs[i,t]\n",
    "            dist_km = dists[i,t] * 6371.0\n",
    "            w = np.exp(-(dist_km/ell_km)**2)\n",
    "            W[i,j] = max(W[i,j], w)\n",
    "            W[j,i] = max(W[j,i], w)\n",
    "\n",
    "    D = np.diag(W.sum(axis=1))\n",
    "    L = (D - W).astype(np.float32)\n",
    "    return W, L\n",
    "\n",
    "def hinge_pos(x): return F.relu(x)\n",
    "\n",
    "def mae_loss(pred, y): return torch.mean(torch.abs(pred - y))\n",
    "\n",
    "def rmse_np(y, yhat): return float(np.sqrt(np.mean((y-yhat)**2)))\n",
    "def mae_np(y, yhat):  return float(np.mean(np.abs(y-yhat)))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_mae_rmse_viol(model, c0, X, y, pm10_tgt, idx, steps, device):\n",
    "    model.eval()\n",
    "    all_y, all_p, all_pm10 = [], [], []\n",
    "\n",
    "    for b0 in range(0, len(idx), BATCH_TIMES):\n",
    "        ii = idx[b0:b0+BATCH_TIMES]\n",
    "        c0b = torch.from_numpy(c0[ii]).to(device)\n",
    "        Xb  = torch.from_numpy(X[ii]).to(device)\n",
    "\n",
    "        pred = model(c0b, Xb, steps)\n",
    "\n",
    "        all_p.append(pred.detach().cpu().numpy())\n",
    "        all_y.append(y[ii])\n",
    "        all_pm10.append(pm10_tgt[ii])\n",
    "\n",
    "    y_true = np.concatenate(all_y, axis=0).reshape(-1)\n",
    "    y_pred = np.concatenate(all_p, axis=0).reshape(-1)\n",
    "    pm10   = np.concatenate(all_pm10, axis=0).reshape(-1)\n",
    "\n",
    "    mae = mae_np(y_true, y_pred)\n",
    "    rmse = rmse_np(y_true, y_pred)\n",
    "    viol = float(np.mean(y_pred > pm10))\n",
    "    return mae, rmse, viol\n",
    "\n",
    "# -----------------------------\n",
    "# Load data once\n",
    "# -----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "keep_cols = [\n",
    "    \"city_id\",\"city_name\",\"lat\",\"lon\",\"datetime\",\n",
    "    \"pm2_5\",\"pm10\",\n",
    "    \"carbon_monoxide\",\"nitrogen_dioxide\",\"sulphur_dioxide\",\"ozone\",\n",
    "    \"doy_sin\",\"doy_cos\",\"hour_sin\",\"hour_cos\"\n",
    "]\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "df = make_lag_features(df, LAGS)\n",
    "df = make_targets(df, H)\n",
    "\n",
    "needed = [f\"pm2_5_lag{l}\" for l in LAGS] + [f\"y_h{H}\", f\"pm10_h{H}\"]\n",
    "df = df.dropna(subset=needed).copy()\n",
    "\n",
    "# city order fixed\n",
    "city_meta = df[[\"city_id\",\"city_name\",\"lat\",\"lon\"]].drop_duplicates().sort_values(\"city_id\").reset_index(drop=True)\n",
    "city_ids = city_meta[\"city_id\"].to_numpy()\n",
    "cid_to_idx = {cid:i for i,cid in enumerate(city_ids)}\n",
    "N = len(city_ids)\n",
    "\n",
    "X_COLS = [\n",
    "    \"carbon_monoxide\",\"nitrogen_dioxide\",\"sulphur_dioxide\",\"ozone\",\n",
    "    \"doy_sin\",\"doy_cos\",\"hour_sin\",\"hour_cos\",\n",
    "] + [f\"pm2_5_lag{l}\" for l in LAGS] + [\"lat\",\"lon\"]\n",
    "\n",
    "def build_time_tensor(df, h):\n",
    "    df2 = df[[\"datetime\",\"city_id\",\"pm2_5\", f\"y_h{h}\", f\"pm10_h{h}\"] + X_COLS].copy()\n",
    "    df2[\"cid_idx\"] = df2[\"city_id\"].map(cid_to_idx)\n",
    "    df2 = df2.sort_values([\"datetime\",\"cid_idx\"])\n",
    "\n",
    "    counts = df2.groupby(\"datetime\")[\"cid_idx\"].nunique()\n",
    "    full_times = counts[counts == N].index\n",
    "    df2 = df2[df2[\"datetime\"].isin(full_times)].copy()\n",
    "\n",
    "    times = pd.to_datetime(np.sort(df2[\"datetime\"].unique()))\n",
    "    T = len(times)\n",
    "\n",
    "    X = np.zeros((T, N, len(X_COLS)), dtype=np.float32)\n",
    "    c0 = np.zeros((T, N, 1), dtype=np.float32)\n",
    "    y  = np.zeros((T, N, 1), dtype=np.float32)\n",
    "    pm10_tgt = np.zeros((T, N, 1), dtype=np.float32)\n",
    "\n",
    "    g = df2.groupby(\"datetime\", sort=True)\n",
    "    for ti, t in enumerate(times):\n",
    "        gt = g.get_group(t).sort_values(\"cid_idx\")\n",
    "        X[ti,:,:] = gt[X_COLS].to_numpy(np.float32)\n",
    "        c0[ti,:,0] = gt[\"pm2_5\"].to_numpy(np.float32)\n",
    "        y[ti,:,0]  = gt[f\"y_h{h}\"].to_numpy(np.float32)\n",
    "        pm10_tgt[ti,:,0] = gt[f\"pm10_h{h}\"].to_numpy(np.float32)\n",
    "\n",
    "    return times, X, c0, y, pm10_tgt\n",
    "\n",
    "times, X, c0, y, pm10_tgt = build_time_tensor(df, H)\n",
    "tr_times, va_times, te_times = time_split_times(times)\n",
    "time_to_i = {t:i for i,t in enumerate(times)}\n",
    "tr_idx = np.array([time_to_i[t] for t in tr_times], dtype=int)\n",
    "va_idx = np.array([time_to_i[t] for t in va_times], dtype=int)\n",
    "te_idx = np.array([time_to_i[t] for t in te_times], dtype=int)\n",
    "\n",
    "# scale once (train only)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[tr_idx].reshape(-1, X.shape[-1]))\n",
    "X = scaler.transform(X.reshape(-1, X.shape[-1])).astype(np.float32).reshape(X.shape)\n",
    "\n",
    "# model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, dropout=0.2, out_dim=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class PIGNN(nn.Module):\n",
    "    def __init__(self, x_dim, L, dt=1.0, gamma=1.0, emb_dim=8, hidden=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "        self.dt = dt\n",
    "        self.gamma = gamma\n",
    "        self.emb = nn.Embedding(N, emb_dim)\n",
    "        self.source = MLP(x_dim + emb_dim, hidden=hidden, dropout=dropout, out_dim=1)\n",
    "        self.D_raw = nn.Parameter(torch.tensor(0.0))\n",
    "        self.k_raw = nn.Parameter(torch.tensor(-1.0))\n",
    "\n",
    "    def D(self): return F.softplus(self.D_raw) + 1e-6\n",
    "    def k(self): return F.softplus(self.k_raw) + 1e-6\n",
    "\n",
    "    def forward(self, c0, X, steps):\n",
    "        B, Nn, Fdim = X.shape\n",
    "        idx = torch.arange(Nn, device=X.device)\n",
    "        e = self.emb(idx)[None,:,:].expand(B, -1, -1)\n",
    "        s = self.source(torch.cat([X, e], dim=-1))\n",
    "\n",
    "        c = c0\n",
    "        D = self.D()\n",
    "        k = self.k()\n",
    "        I = torch.eye(self.L.shape[0], device=c.device, dtype=c.dtype)\n",
    "        A = I + self.gamma * self.dt * D * self.L + self.dt * k * I\n",
    "\n",
    "        for _ in range(steps):\n",
    "            Lc = torch.einsum(\"ij,bjk->bik\", self.L, c)\n",
    "            rhs = c + self.dt * ((1 - self.gamma) * D * (-Lc) + s)\n",
    "            c = torch.linalg.solve(A.expand(rhs.shape[0], -1, -1), rhs)\n",
    "\n",
    "        return c\n",
    "\n",
    "# Train loop for each k\n",
    "results=[]\n",
    "all_pred=[]\n",
    "\n",
    "for k_graph in K_LIST:\n",
    "    # rebuild graph Laplacian for this k\n",
    "    Wk, Lk_np = build_knn_graph(city_meta, k=k_graph, ell_km=ELL_KM)\n",
    "    Lk = torch.tensor(Lk_np, device=DEVICE)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"PI-GNN | h=24 | k={k_graph}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model = PIGNN(x_dim=X.shape[-1], L=Lk, dt=DT, gamma=GAMMA, hidden=64, dropout=DROPOUT).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val = 1e18\n",
    "    best_state=None\n",
    "    bad=0\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        np.random.shuffle(tr_idx)\n",
    "        tr_losses=[]\n",
    "\n",
    "        for b0 in range(0, len(tr_idx), BATCH_TIMES):\n",
    "            ii = tr_idx[b0:b0+BATCH_TIMES]\n",
    "            c0b = torch.from_numpy(c0[ii]).to(DEVICE)\n",
    "            Xb  = torch.from_numpy(X[ii]).to(DEVICE)\n",
    "            yb  = torch.from_numpy(y[ii]).to(DEVICE)\n",
    "            pm10b = torch.from_numpy(pm10_tgt[ii]).to(DEVICE)\n",
    "\n",
    "            pred = model(c0b, Xb, H)\n",
    "\n",
    "            loss = mae_loss(pred, yb)\n",
    "            loss = loss + LAMBDA_INEQ * torch.mean(hinge_pos(pred - pm10b))\n",
    "            loss = loss + LAMBDA_NONNEG * torch.mean(hinge_pos(-pred))\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        val_mae, val_rmse, val_viol = eval_mae_rmse_viol(model, c0, X, y, pm10_tgt, va_idx, H, DEVICE)\n",
    "        print(f\"[k={k_graph}] ep {ep:02d} | train {np.mean(tr_losses):.4f} | \"\n",
    "              f\"val_MAE {val_mae:.4f} | val_RMSE {val_rmse:.4f} | val_viol {100*val_viol:.2f}% | \"\n",
    "              f\"D {model.D().item():.4f} k {model.k().item():.4f}\")\n",
    "\n",
    "        if val_mae < best_val - 1e-4:\n",
    "            best_val = val_mae\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            bad=0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= PATIENCE:\n",
    "                print(f\"[k={k_graph}] Early stop. Best val_MAE={best_val:.4f}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # final val/test\n",
    "    val_mae, val_rmse, val_viol = eval_mae_rmse_viol(model, c0, X, y, pm10_tgt, va_idx, H, DEVICE)\n",
    "    te_mae, te_rmse, te_viol = eval_mae_rmse_viol(model, c0, X, y, pm10_tgt, te_idx, H, DEVICE)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": \"PI-GNN\",\n",
    "        \"k_graph\": k_graph,\n",
    "        \"horizon_h\": H,\n",
    "        \"val_MAE\": val_mae, \"val_RMSE\": val_rmse, \"val_viol_rate\": val_viol,\n",
    "        \"test_MAE\": te_mae, \"test_RMSE\": te_rmse, \"test_viol_rate\": te_viol,\n",
    "        \"D_eff\": float(model.D().item()),\n",
    "        \"k_eff\": float(model.k().item()),\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(OUT_MET, index=False)\n",
    "print(\"\\nSaved:\", OUT_MET)\n",
    "print(res_df.sort_values(\"test_MAE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f9d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
